{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas_datareader as wb\n",
    "from pandas_datareader import data\n",
    "import yfinance as yf\n",
    "import requests \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from lxml import html\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_treasury_rate():\n",
    "    \n",
    "    url = 'https://www.treasury.gov/resource-center/data-chart-center/interest-rates/Pages/TextView.aspx?data=yield'\n",
    "    r = requests.get(url)\n",
    "    html = r.text\n",
    "\n",
    "    soup = BeautifulSoup(html)\n",
    "    table = soup.find('table', {\"class\": \"t-chart\"})\n",
    "    rows = table.find_all('tr')\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        cols = [ele.text.strip() for ele in cols]\n",
    "        data.append([ele for ele in cols if ele])\n",
    "\n",
    "        result = pd.DataFrame(data, columns=['Date', '1 Mo', '2 Mo', '3 Mo', '6 Mo', '1 Yr', '2 Yr', '3 Yr', '5 Yr', '7 Yr', '10 Yr', '20 Yr', '30 Yr'])\n",
    "\n",
    "    return(result)\n",
    "\n",
    "\n",
    "\n",
    "def return_df(close_price_df):\n",
    "        \n",
    "    return_df = close_price_df.pct_change().apply(lambda x: np.log(1+x))\n",
    "    \n",
    "    return return_df\n",
    "\n",
    "\n",
    "def port_simulation(stock_closed_df, freq = \"D\"):\n",
    "    \n",
    "    days_per_freq = {\"D\": 1, \"W\": 5, \"M\": 21, \"Y\": 250}\n",
    "    \n",
    "    pct_change_df = stock_closed_df.pct_change()\n",
    "    period_pct_change = pct_change_df.resample(freq).mean()\n",
    "    ind_er = period_pct_change.mean()\n",
    "    return_df = pct_change_df.apply(lambda x: np.log(1+x))\n",
    "    cov_matrix = return_df.cov()\n",
    "    \n",
    "    p_ret = [] \n",
    "    p_vol = [] \n",
    "    p_weights = [] \n",
    "    \n",
    "    \n",
    "    num_assets = len(stock_closed_df.columns)\n",
    "    num_portfolios = 10000\n",
    "\n",
    "    \n",
    "    for portfolio in range(num_portfolios):\n",
    "        weights = np.random.random(num_assets)\n",
    "        weights = weights/np.sum(weights)\n",
    "        p_weights.append(weights)\n",
    "        returns = np.dot(weights, ind_er)  \n",
    "        p_ret.append(returns)\n",
    "        var = cov_matrix.mul(weights, axis=0).mul(weights, axis=1).sum().sum()\n",
    "        sd = np.sqrt(var) \n",
    "        freq_sd = sd*np.sqrt(days_per_freq[freq]) \n",
    "        p_vol.append(freq_sd)\n",
    "    \n",
    "    data = {'Returns':p_ret, 'Volatility':p_vol}\n",
    " \n",
    "    for counter, symbol in enumerate(stock_closed_df.columns.tolist()):\n",
    "        data[symbol+' weight'] = [w[counter] for w in p_weights]\n",
    "        portfolios  = pd.DataFrame(data)\n",
    "        \n",
    "    return portfolios\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FF_assign_label(index_comp_info):\n",
    "        \n",
    "        \n",
    "    index_comp_info[\"bookToMarket\"] = 1/index_comp_info[\"PB_ratio\"]\n",
    "    index_comp_info[\"Small_Big_Cap\"] = index_comp_info[\"mkt_cap\"].map(lambda x: \"B\" if x >= index_comp_info[\"mkt_cap\"].median() else \"S\")\n",
    "    \n",
    "    lower, upper = index_comp_info[\"bookToMarket\"].quantile([0.3, 0.7])\n",
    "    index_comp_info[\"HML_BP\"] = index_comp_info[\"bookToMarket\"].map(lambda x: \"H\" if x >= upper else \"M\")\n",
    "    index_comp_info[\"HML_BP\"] = index_comp_info.apply(lambda row: \"L\" if row[\"bookToMarket\"] <= lower else row[\"HML_BP\"], axis = 1)\n",
    "    \n",
    "    lower_roe, upper_roe = index_comp_info[\"ROE\"].quantile([0.3, 0.7])\n",
    "    index_comp_info[\"RNW_ROE\"] = index_comp_info[\"ROE\"].map(lambda x: \"R\" if x >= upper_roe else \"N\")\n",
    "    index_comp_info[\"RNW_ROE\"] = index_comp_info.apply(lambda row: \"W\" if row[\"ROE\"] <= lower_roe else row[\"RNW_ROE\"], axis = 1)\n",
    "    \n",
    "    lower_invest, upper_invest = index_comp_info[\"Asset_growth\"].quantile([0.3, 0.7])\n",
    "    index_comp_info[\"ANC_investment\"] = index_comp_info[\"Asset_growth\"].map(lambda x: \"A\" if x >= upper_invest else \"N\")\n",
    "    index_comp_info[\"ANC_investment\"] = index_comp_info.apply(lambda row: \"C\" if row[\"Asset_growth\"] <= lower_invest else row[\"ANC_investment\"], axis = 1)\n",
    "            \n",
    "    return index_comp_info\n",
    "        \n",
    "def FF_factor_classifier(index_comp_info_with_label):\n",
    "        \n",
    "    data = index_comp_info_with_label\n",
    "    Small_Low = data.query('(Small_Big_Cap==\"S\") & (HML_BP==\"L\")')\n",
    "    Small_Mid = data.query('(Small_Big_Cap==\"S\") & (HML_BP==\"M\")')\n",
    "    Small_High = data.query('(Small_Big_Cap==\"S\") & (HML_BP==\"H\")')\n",
    "    \n",
    "    Small_Weak = data.query('(Small_Big_Cap==\"S\") & (RNW_ROE==\"W\")')\n",
    "    Small_Neutral_Profit = data.query('(Small_Big_Cap==\"S\") & (RNW_ROE==\"N\")')\n",
    "    Small_Robust = data.query('(Small_Big_Cap==\"S\") & (RNW_ROE==\"R\")')\n",
    "    \n",
    "    Small_Conservative =  data.query('(Small_Big_Cap==\"S\") & (ANC_investment==\"C\")')\n",
    "    Small_Neutral_Invest =  data.query('(Small_Big_Cap==\"S\") & (ANC_investment==\"N\")')\n",
    "    Small_Aggresive =  data.query('(Small_Big_Cap==\"S\") & (ANC_investment==\"A\")')\n",
    "    \n",
    "    Big_Low = data.query('(Small_Big_Cap==\"B\") & (HML_BP==\"L\")')\n",
    "    Big_Mid = data.query('(Small_Big_Cap==\"B\") & (HML_BP==\"M\")')\n",
    "    Big_High = data.query('(Small_Big_Cap==\"B\") & (HML_BP==\"H\")')\n",
    "    \n",
    "    Big_Weak = data.query('(Small_Big_Cap==\"B\") & (RNW_ROE==\"W\")')\n",
    "    Big_Neutral_Profit = data.query('(Small_Big_Cap==\"B\") & (RNW_ROE==\"N\")')\n",
    "    Big_Robust = data.query('(Small_Big_Cap==\"B\") & (RNW_ROE==\"R\")')\n",
    "\n",
    "    Big_Conservative =  data.query('(Small_Big_Cap==\"B\") & (ANC_investment==\"C\")')\n",
    "    Big_Neutral_Invest = data.query('(Small_Big_Cap==\"B\") & (ANC_investment==\"N\")')\n",
    "    Big_Aggresive =  data.query('(Small_Big_Cap==\"B\") & (ANC_investment==\"A\")')\n",
    "    \n",
    "    each_groups_list = [Small_Low, Small_Mid, Small_High, \n",
    "                            Small_Weak, Small_Neutral_Profit, Small_Robust,\n",
    "                            Small_Conservative, Small_Neutral_Invest, Small_Aggresive,\n",
    "                            Big_Low, Big_Mid,Big_High,\n",
    "                            Big_Weak, Big_Neutral_Profit, Big_Robust,\n",
    "                            Big_Conservative, Big_Neutral_Invest, Big_Aggresive]\n",
    "        \n",
    "    return each_groups_list\n",
    "    \n",
    "def FF_classes_return(market_components_return, list_of_group_info, axis=True):\n",
    "        \n",
    "    groups_names = [\"Small_Low\", \"Small_Mid\", \"Small_High\",\n",
    "                        \"Small_Weak\", \"Small_Neutral_Profit\", \"Small_Robust\",\n",
    "                        \"Small_Cons\", \"Small_Neutral_Invest\", \"Small_Aggr\",\n",
    "                        \"Big_Low\", \"Big_Mid\",\"Big_High\",\n",
    "                        \"Big_Weak\", \"Big_Neutral_Profit\", \"Big_Robust\",\n",
    "                        \"Big_Cons\", \"Big_Neutral_Invest\", \"Big_Aggr\"]\n",
    "    \n",
    "    df_groups = pd.DataFrame(columns = groups_names)\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    for group in list_of_group_info:\n",
    "    \n",
    "        group_cap = group[\"mkt_cap\"].T\n",
    "        group_total_cap = group[\"mkt_cap\"].sum()\n",
    "        group_cap_multi_return = group_cap*market_components_return[list(group.index)]\n",
    "        \n",
    "        if axis == True:\n",
    "            df_groups[groups_names[counter]] = group_cap_multi_return.apply(lambda row: row.sum()/group_total_cap, axis=1)\n",
    "        \n",
    "        else:\n",
    "            groups_index_return = group_cap_multi_return.sum()/group_total_cap\n",
    "            df_groups[groups_names[counter]] = [groups_index_return]\n",
    "    \n",
    "        counter += 1\n",
    "                \n",
    "    return df_groups\n",
    "    \n",
    "def FF_calc_factors(classes_return_df, df = True):\n",
    "    \n",
    "    factor_name = [\"SMB\", \"HML\", \"RMW\", \"CMA\"]\n",
    "    \n",
    "    SMB_BP = (classes_return_df[\"Small_Low\"] + classes_return_df[\"Small_Mid\"] \n",
    "                      + classes_return_df[\"Small_High\"]) - (classes_return_df[\"Big_Low\"]\n",
    "                      + classes_return_df[\"Big_Mid\"] + classes_return_df[\"Big_High\"])/3\n",
    "    \n",
    "    SMB_PFT = (classes_return_df[\"Small_Weak\"] + classes_return_df[\"Small_Neutral_Profit\"] \n",
    "                      + classes_return_df[\"Small_Robust\"]) - (classes_return_df[\"Big_Weak\"]\n",
    "                      + classes_return_df[\"Big_Neutral_Profit\"] + classes_return_df[\"Big_Robust\"])/3\n",
    "    \n",
    "    SMB_INV = (classes_return_df[\"Small_Cons\"] + classes_return_df[\"Small_Neutral_Invest\"] \n",
    "                      + classes_return_df[\"Small_Aggr\"]) - (classes_return_df[\"Big_Cons\"]\n",
    "                      + classes_return_df[\"Big_Neutral_Invest\"] + classes_return_df[\"Big_Aggr\"])/3\n",
    "    \n",
    "    if df == True:\n",
    "        \n",
    "        FF_factors_data = pd.DataFrame(columns = factor_name)\n",
    "        \n",
    "    \n",
    "    FF_factors_data[\"SMB\"] = (SMB_BP + SMB_PFT + SMB_INV)/3\n",
    "    \n",
    "    FF_factors_data[\"HML\"] = (classes_return_df[\"Small_High\"] + classes_return_df[\"Big_High\"]\n",
    "                      - (classes_return_df[\"Small_Low\"] + classes_return_df[\"Big_Low\"])) / 2\n",
    "    \n",
    "    FF_factors_data[\"RMW\"] = (classes_return_df[\"Small_Robust\"] + classes_return_df[\"Big_Robust\"]\n",
    "                      - (classes_return_df[\"Small_Weak\"] + classes_return_df[\"Big_Weak\"])) / 2\n",
    "    \n",
    "    FF_factors_data[\"CMA\"] = (classes_return_df[\"Small_Cons\"] + classes_return_df[\"Big_Cons\"]\n",
    "                      - (classes_return_df[\"Small_Aggr\"] + classes_return_df[\"Big_Aggr\"])) / 2\n",
    "        \n",
    "    return FF_factors_data\n",
    "\n",
    "    \n",
    "def FF_regress(FF_factors_df, target_comp_return, Rf):\n",
    "        \n",
    "    target_comp_return = target_comp_return - Rf\n",
    "        \n",
    "        \n",
    "    y = target_comp_return\n",
    "    x = FF_factors_df\n",
    "    X = sm.add_constant(x)\n",
    "    model = sm.OLS(y.astype(float), X.astype(float))\n",
    "    result = model.fit()\n",
    " \n",
    "    print(result.summary())\n",
    "    print('\\n\\n')\n",
    "\n",
    "    \n",
    "    return result\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frequency: 30 min and 2 min\n",
    "\n",
    "Time series Beta estimation: Measure 5 betas for each 30 min, using 2 min frequency. (Need to know how betas change every 30 min)\n",
    "\n",
    "Model Construction:\n",
    "\n",
    "1) model the probability of 30 min winning with 5 betas(5 features) we eatimate every 30 min. (can use SVM, decision tree, regression...)\n",
    "\n",
    "2) measure betas of winner-loser portfolios spread for same time length for our portolios\n",
    "\n",
    "3) plug betas of portfolios to the model in 1)\n",
    "\n",
    "4) model true prob of winning of portfolios on fitted value from 3)\n",
    "\n",
    "5) make analyical model to preidictive model\n",
    "\n",
    "The reason we estimate the probability of picking a winner portfolio with given beta is because as we move from Time(T) T1 to T2, the stock price changes, so our weight also changes. We are essensially move from one simulated portfolio to another simulated portfolio as the time goes.\n",
    "\n",
    "\n",
    "What ML can apply here?\n",
    "\n",
    "What would the result be if use unsupervised grouping to caculate factors? (Maybe useful when FF doesn't explain well in term of R^2)\n",
    "\n",
    "Any potential non-linear relationship?\n",
    "\n",
    "How to optimize time scale to ensure the highest predictive ability? or would models' ability consistant accross time series mapping?\n",
    "\n",
    "How to test predictivity?\n",
    "\n",
    "Any trade off between high winning prob and portfolio sharpe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "FF_info = pd.read_csv(\"data/Fama_French_info.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = ' '\n",
    "index_list = FF_info.index.tolist()\n",
    "index_list.append(\"SPY\")\n",
    "#index_list.reverse()\n",
    "total_string = str1.join(index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPYn500_30m_df = yf.download(total_string, start = '2021-10-11', end = \"2021-11-18\", interval = '30m')\n",
    "#SPYn500_2m_df = yf.download(total_string, start = '2021-10-11', end = \"2021-11-18\", interval = '2m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPYn500_30m_df[\"Adj Close\"].to_csv(\"SPYn500_30m_close.csv\")\n",
    "#SPYn500_2m_df[\"Adj Close\"].to_csv(\"SPYn500_2m_close.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_2m_close = pd.read_csv(\"data/SPYn500_2m_close.csv\", index_col = 0)\n",
    "sp_30m_close = pd.read_csv(\"data/SPYn500_30m_close.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:30:00-04:00</th>\n",
       "      <td>150.729996</td>\n",
       "      <td>20.120001</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>141.949997</td>\n",
       "      <td>111.199997</td>\n",
       "      <td>120.519997</td>\n",
       "      <td>333.580200</td>\n",
       "      <td>118.260002</td>\n",
       "      <td>324.829987</td>\n",
       "      <td>571.551025</td>\n",
       "      <td>...</td>\n",
       "      <td>61.740002</td>\n",
       "      <td>154.020004</td>\n",
       "      <td>62.622299</td>\n",
       "      <td>58.139999</td>\n",
       "      <td>121.169998</td>\n",
       "      <td>123.730003</td>\n",
       "      <td>146.309998</td>\n",
       "      <td>492.000000</td>\n",
       "      <td>64.209999</td>\n",
       "      <td>196.289993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:32:00-04:00</th>\n",
       "      <td>150.690002</td>\n",
       "      <td>20.020000</td>\n",
       "      <td>213.889999</td>\n",
       "      <td>142.850006</td>\n",
       "      <td>111.160004</td>\n",
       "      <td>121.260002</td>\n",
       "      <td>333.104889</td>\n",
       "      <td>118.154999</td>\n",
       "      <td>325.119995</td>\n",
       "      <td>574.900024</td>\n",
       "      <td>...</td>\n",
       "      <td>62.064999</td>\n",
       "      <td>155.339996</td>\n",
       "      <td>62.560001</td>\n",
       "      <td>58.119999</td>\n",
       "      <td>121.239998</td>\n",
       "      <td>123.787201</td>\n",
       "      <td>146.315002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.900002</td>\n",
       "      <td>196.509995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:34:00-04:00</th>\n",
       "      <td>151.330002</td>\n",
       "      <td>19.870001</td>\n",
       "      <td>214.000000</td>\n",
       "      <td>142.889999</td>\n",
       "      <td>111.129997</td>\n",
       "      <td>121.184998</td>\n",
       "      <td>335.989990</td>\n",
       "      <td>118.599998</td>\n",
       "      <td>324.910004</td>\n",
       "      <td>575.900024</td>\n",
       "      <td>...</td>\n",
       "      <td>62.360001</td>\n",
       "      <td>155.895004</td>\n",
       "      <td>62.556599</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>120.980003</td>\n",
       "      <td>123.180000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.650002</td>\n",
       "      <td>196.820007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:36:00-04:00</th>\n",
       "      <td>150.720001</td>\n",
       "      <td>19.925501</td>\n",
       "      <td>213.960007</td>\n",
       "      <td>142.619995</td>\n",
       "      <td>111.165001</td>\n",
       "      <td>121.589996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.139999</td>\n",
       "      <td>324.929993</td>\n",
       "      <td>574.859985</td>\n",
       "      <td>...</td>\n",
       "      <td>62.310001</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>62.770000</td>\n",
       "      <td>57.939999</td>\n",
       "      <td>121.135002</td>\n",
       "      <td>123.209999</td>\n",
       "      <td>146.500000</td>\n",
       "      <td>493.440002</td>\n",
       "      <td>63.750000</td>\n",
       "      <td>196.669998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:38:00-04:00</th>\n",
       "      <td>151.080002</td>\n",
       "      <td>19.940001</td>\n",
       "      <td>213.809998</td>\n",
       "      <td>143.059998</td>\n",
       "      <td>110.995003</td>\n",
       "      <td>121.919998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.010002</td>\n",
       "      <td>325.589996</td>\n",
       "      <td>575.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>62.139999</td>\n",
       "      <td>156.729996</td>\n",
       "      <td>62.509499</td>\n",
       "      <td>58.049000</td>\n",
       "      <td>121.269997</td>\n",
       "      <td>123.379997</td>\n",
       "      <td>146.690002</td>\n",
       "      <td>494.079987</td>\n",
       "      <td>63.680000</td>\n",
       "      <td>196.770004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    A        AAL         AAP        AAPL  \\\n",
       "Datetime                                                                   \n",
       "2021-10-11 09:30:00-04:00  150.729996  20.120001  214.000000  141.949997   \n",
       "2021-10-11 09:32:00-04:00  150.690002  20.020000  213.889999  142.850006   \n",
       "2021-10-11 09:34:00-04:00  151.330002  19.870001  214.000000  142.889999   \n",
       "2021-10-11 09:36:00-04:00  150.720001  19.925501  213.960007  142.619995   \n",
       "2021-10-11 09:38:00-04:00  151.080002  19.940001  213.809998  143.059998   \n",
       "\n",
       "                                 ABBV         ABC        ABMD         ABT  \\\n",
       "Datetime                                                                    \n",
       "2021-10-11 09:30:00-04:00  111.199997  120.519997  333.580200  118.260002   \n",
       "2021-10-11 09:32:00-04:00  111.160004  121.260002  333.104889  118.154999   \n",
       "2021-10-11 09:34:00-04:00  111.129997  121.184998  335.989990  118.599998   \n",
       "2021-10-11 09:36:00-04:00  111.165001  121.589996         NaN  118.139999   \n",
       "2021-10-11 09:38:00-04:00  110.995003  121.919998         NaN  118.010002   \n",
       "\n",
       "                                  ACN        ADBE  ...        XEL        XLNX  \\\n",
       "Datetime                                           ...                          \n",
       "2021-10-11 09:30:00-04:00  324.829987  571.551025  ...  61.740002  154.020004   \n",
       "2021-10-11 09:32:00-04:00  325.119995  574.900024  ...  62.064999  155.339996   \n",
       "2021-10-11 09:34:00-04:00  324.910004  575.900024  ...  62.360001  155.895004   \n",
       "2021-10-11 09:36:00-04:00  324.929993  574.859985  ...  62.310001  156.000000   \n",
       "2021-10-11 09:38:00-04:00  325.589996  575.750000  ...  62.139999  156.729996   \n",
       "\n",
       "                                 XOM       XRAY         XYL         YUM  \\\n",
       "Datetime                                                                  \n",
       "2021-10-11 09:30:00-04:00  62.622299  58.139999  121.169998  123.730003   \n",
       "2021-10-11 09:32:00-04:00  62.560001  58.119999  121.239998  123.787201   \n",
       "2021-10-11 09:34:00-04:00  62.556599  58.000000  120.980003  123.180000   \n",
       "2021-10-11 09:36:00-04:00  62.770000  57.939999  121.135002  123.209999   \n",
       "2021-10-11 09:38:00-04:00  62.509499  58.049000  121.269997  123.379997   \n",
       "\n",
       "                                  ZBH        ZBRA       ZION         ZTS  \n",
       "Datetime                                                                  \n",
       "2021-10-11 09:30:00-04:00  146.309998  492.000000  64.209999  196.289993  \n",
       "2021-10-11 09:32:00-04:00  146.315002         NaN  63.900002  196.509995  \n",
       "2021-10-11 09:34:00-04:00         NaN         NaN  63.650002  196.820007  \n",
       "2021-10-11 09:36:00-04:00  146.500000  493.440002  63.750000  196.669998  \n",
       "2021-10-11 09:38:00-04:00  146.690002  494.079987  63.680000  196.770004  \n",
       "\n",
       "[5 rows x 506 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_2m_close.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate log-return (assuming return is log-normal) for both time interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_2m_return = return_df(sp_2m_close)\n",
    "total_30m_return = return_df(sp_30m_close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_2m_return = total_2m_return.drop(columns=[\"SPY\"]).dropna(how=\"all\")\n",
    "sp500_2m_volatility = sp500_2m_return.std()\n",
    "sp500_30m_return = total_30m_return.drop(columns=[\"SPY\"]).dropna(how=\"all\")\n",
    "sp500_30m_volatility = sp500_30m_return.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp500_2m_return = sp500_2m_return.drop(columns = list(FF_info[FF_info[\"mkt_cap\"].isna()].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>ABT</th>\n",
       "      <th>ACN</th>\n",
       "      <th>ADBE</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL</th>\n",
       "      <th>XLNX</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:32:00-04:00</th>\n",
       "      <td>-0.000265</td>\n",
       "      <td>-0.004983</td>\n",
       "      <td>-0.000514</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>-0.000360</td>\n",
       "      <td>0.006121</td>\n",
       "      <td>-0.001426</td>\n",
       "      <td>-0.000888</td>\n",
       "      <td>0.000892</td>\n",
       "      <td>0.005842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005250</td>\n",
       "      <td>0.008534</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>-0.000344</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.004840</td>\n",
       "      <td>0.001120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:34:00-04:00</th>\n",
       "      <td>0.004238</td>\n",
       "      <td>-0.007521</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.000619</td>\n",
       "      <td>0.008624</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>-0.000646</td>\n",
       "      <td>0.001738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>-0.000054</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.002147</td>\n",
       "      <td>-0.004917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003920</td>\n",
       "      <td>0.001576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:36:00-04:00</th>\n",
       "      <td>-0.004039</td>\n",
       "      <td>0.002789</td>\n",
       "      <td>-0.000187</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.003886</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>-0.001808</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000802</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.003406</td>\n",
       "      <td>-0.001035</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.001570</td>\n",
       "      <td>-0.000762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:38:00-04:00</th>\n",
       "      <td>0.002386</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>0.003080</td>\n",
       "      <td>-0.001530</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.001547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002732</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>-0.004159</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.001379</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>-0.001099</td>\n",
       "      <td>0.000508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:40:00-04:00</th>\n",
       "      <td>-0.001159</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>0.003781</td>\n",
       "      <td>0.001810</td>\n",
       "      <td>-0.000766</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.002170</td>\n",
       "      <td>-0.001526</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.001874</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.003185</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.003635</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.001099</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 505 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  A       AAL       AAP      AAPL      ABBV  \\\n",
       "Datetime                                                                      \n",
       "2021-10-11 09:32:00-04:00 -0.000265 -0.004983 -0.000514  0.006320 -0.000360   \n",
       "2021-10-11 09:34:00-04:00  0.004238 -0.007521  0.000514  0.000280 -0.000270   \n",
       "2021-10-11 09:36:00-04:00 -0.004039  0.002789 -0.000187 -0.001891  0.000315   \n",
       "2021-10-11 09:38:00-04:00  0.002386  0.000727 -0.000701  0.003080 -0.001530   \n",
       "2021-10-11 09:40:00-04:00 -0.001159  0.001002  0.003781  0.001810 -0.000766   \n",
       "\n",
       "                                ABC      ABMD       ABT       ACN      ADBE  \\\n",
       "Datetime                                                                      \n",
       "2021-10-11 09:32:00-04:00  0.006121 -0.001426 -0.000888  0.000892  0.005842   \n",
       "2021-10-11 09:34:00-04:00 -0.000619  0.008624  0.003759 -0.000646  0.001738   \n",
       "2021-10-11 09:36:00-04:00  0.003336  0.000000 -0.003886  0.000062 -0.001808   \n",
       "2021-10-11 09:38:00-04:00  0.002710  0.000000 -0.001101  0.002029  0.001547   \n",
       "2021-10-11 09:40:00-04:00  0.001066  0.002170 -0.001526  0.001258  0.001874   \n",
       "\n",
       "                           ...       XEL      XLNX       XOM      XRAY  \\\n",
       "Datetime                   ...                                           \n",
       "2021-10-11 09:32:00-04:00  ...  0.005250  0.008534 -0.000995 -0.000344   \n",
       "2021-10-11 09:34:00-04:00  ...  0.004742  0.003566 -0.000054 -0.002067   \n",
       "2021-10-11 09:36:00-04:00  ... -0.000802  0.000673  0.003406 -0.001035   \n",
       "2021-10-11 09:38:00-04:00  ... -0.002732  0.004669 -0.004159  0.001880   \n",
       "2021-10-11 09:40:00-04:00  ...  0.000804  0.003185  0.001606  0.000017   \n",
       "\n",
       "                                XYL       YUM       ZBH      ZBRA      ZION  \\\n",
       "Datetime                                                                      \n",
       "2021-10-11 09:32:00-04:00  0.000578  0.000462  0.000034  0.000000 -0.004840   \n",
       "2021-10-11 09:34:00-04:00 -0.002147 -0.004917  0.000000  0.000000 -0.003920   \n",
       "2021-10-11 09:36:00-04:00  0.001280  0.000244  0.001264  0.002923  0.001570   \n",
       "2021-10-11 09:38:00-04:00  0.001114  0.001379  0.001296  0.001296 -0.001099   \n",
       "2021-10-11 09:40:00-04:00 -0.003635  0.000081  0.000273  0.006416  0.001099   \n",
       "\n",
       "                                ZTS  \n",
       "Datetime                             \n",
       "2021-10-11 09:32:00-04:00  0.001120  \n",
       "2021-10-11 09:34:00-04:00  0.001576  \n",
       "2021-10-11 09:36:00-04:00 -0.000762  \n",
       "2021-10-11 09:38:00-04:00  0.000508  \n",
       "2021-10-11 09:40:00-04:00  0.000102  \n",
       "\n",
       "[5 rows x 505 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp500_2m_return.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rm_30m = total_30m_return[['SPY']]\n",
    "Rm_2m = total_2m_return[['SPY']]\n",
    "#We need to discount Monthly Rf to 2m and 30m Rf using yield curve(continuously compounded)\n",
    "Rf = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_2m_sharpe = (Rm_2m - Rf)/Rm_2m.std()\n",
    "market_2m_sharpe = market_2m_sharpe.dropna()\n",
    "market_30m_sharpe = (Rm_30m - Rf)/Rm_30m.std()\n",
    "market_30m_sharpe = market_30m_sharpe.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_2m_sharpe = (sp500_2m_return - Rf)/sp500_2m_volatility\n",
    "sp500_2m_sharpe = sp500_2m_sharpe.dropna(how=\"all\")\n",
    "sp500_30m_sharpe = (sp500_30m_return - Rf)/sp500_30m_volatility\n",
    "sp500_30m_sharpe = sp500_30m_sharpe.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the index columns doesn't match for some reasons, need to fix !\n",
    "sp500_2m_sharpe_excess = sp500_2m_sharpe.subtract(market_2m_sharpe.values, axis=0)\n",
    "sp500_30m_sharpe_excess = sp500_30m_sharpe.subtract(market_30m_sharpe.values, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling spread between winner return and loser return on FF5F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate FF factors for lower freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_2m_beaters = sp500_2m_sharpe_excess.copy()\n",
    "dummies_2m_beaters[dummies_2m_beaters >= 0] =1\n",
    "dummies_2m_beaters[dummies_2m_beaters < 0] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please tell me there is a faster way to do this\n",
    "#FF_info_clean = FF_info.drop(FF_info[\"mkt_cap\"].isna().index)\n",
    "def FF_spread_calc(dummies_2m_beaters ,sp500_2m_return, FF_info): \n",
    "\n",
    "    WML = pd.DataFrame(index = sp500_2m_return.index, columns = [\"winner_return\", \"loser_return\", \"R_WML\", \"SMB_WML\", \"HML_WML\", \"RMW_WML\", \"CMA_WML\"])\n",
    "\n",
    "\n",
    "    for i in tqdm(range(len(sp500_2m_return.index))):\n",
    "    \n",
    "        beaters_2m = []\n",
    "        losers_2m = []\n",
    "    \n",
    "        \n",
    "        for j in range(len(dummies_2m_beaters.columns)):\n",
    "        \n",
    "            if dummies_2m_beaters.iloc[i][j] == 1:\n",
    "                beaters_2m.append(dummies_2m_beaters.columns[j])\n",
    "            \n",
    "            else:\n",
    "                losers_2m.append(dummies_2m_beaters.columns[j])\n",
    "        \n",
    "        winners_info = FF_info.loc[beaters_2m]\n",
    "        losers_info = FF_info.loc[losers_2m]\n",
    "    \n",
    "        winners_cap = winners_info[\"mkt_cap\"].T\n",
    "        losers_cap = losers_info[\"mkt_cap\"].T\n",
    "    \n",
    "        winner_index_return = (sp500_2m_return.iloc[i][beaters_2m]*winners_cap).T.sum()/winners_cap.sum()\n",
    "        loser_index_return = (sp500_2m_return.iloc[i][losers_2m]*losers_cap).T.sum()/losers_cap.sum()\n",
    "    \n",
    "        WML.iloc[i][\"winner_return\"] = winner_index_return\n",
    "        WML.iloc[i][\"loser_return\"] = loser_index_return\n",
    "        WML.iloc[i][\"R_WML\"] = winner_index_return - loser_index_return\n",
    "\n",
    "        winners_with_labels = FF_assign_label(winners_info)\n",
    "        winners_subset_list = FF_factor_classifier(winners_with_labels)\n",
    "        winners_groups_return = FF_classes_return(sp500_2m_return.iloc[i][beaters_2m] ,winners_subset_list, axis=False)\n",
    "        winner_factors = FF_calc_factors(winners_groups_return)\n",
    "    \n",
    "    \n",
    "        losers_with_labels = FF_assign_label(losers_info)\n",
    "        losers_subset_list = FF_factor_classifier(losers_with_labels)\n",
    "        losers_groups_return = FF_classes_return(sp500_2m_return.iloc[i][losers_2m] ,losers_subset_list, axis=False)\n",
    "        losers_factors = FF_calc_factors(losers_groups_return)\n",
    "    \n",
    "        factors_spread = winner_factors - losers_factors\n",
    "        spread_to_list = factors_spread.values[0].tolist()\n",
    "        WML.iloc[i][\"SMB_WML\", \"HML_WML\", \"RMW_WML\", \"CMA_WML\"] = spread_to_list\n",
    "        \n",
    "        return WML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>winner_return</th>\n",
       "      <th>loser_return</th>\n",
       "      <th>R_WML</th>\n",
       "      <th>SMB_WML</th>\n",
       "      <th>HML_WML</th>\n",
       "      <th>RMW_WML</th>\n",
       "      <th>CMA_WML</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:32:00-04:00</th>\n",
       "      <td>0.005410</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>0.013753</td>\n",
       "      <td>0.001752</td>\n",
       "      <td>-0.001094</td>\n",
       "      <td>0.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:34:00-04:00</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>-0.004206</td>\n",
       "      <td>0.004343</td>\n",
       "      <td>0.010615</td>\n",
       "      <td>-0.001710</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>-0.000463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:36:00-04:00</th>\n",
       "      <td>0.002140</td>\n",
       "      <td>-0.001644</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>-0.000403</td>\n",
       "      <td>-0.000388</td>\n",
       "      <td>0.001155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:38:00-04:00</th>\n",
       "      <td>0.002154</td>\n",
       "      <td>-0.000701</td>\n",
       "      <td>0.002855</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>-0.000324</td>\n",
       "      <td>-0.000832</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-11 09:40:00-04:00</th>\n",
       "      <td>0.002637</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>-0.001392</td>\n",
       "      <td>-0.000229</td>\n",
       "      <td>0.000156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           winner_return  loser_return     R_WML   SMB_WML  \\\n",
       "Datetime                                                                     \n",
       "2021-10-11 09:32:00-04:00       0.005410      0.000192  0.005218  0.013753   \n",
       "2021-10-11 09:34:00-04:00       0.000137     -0.004206  0.004343  0.010615   \n",
       "2021-10-11 09:36:00-04:00       0.002140     -0.001644  0.003785  0.009454   \n",
       "2021-10-11 09:38:00-04:00       0.002154     -0.000701  0.002855  0.009562   \n",
       "2021-10-11 09:40:00-04:00       0.002637      0.000114  0.002524  0.008173   \n",
       "\n",
       "                            HML_WML   RMW_WML   CMA_WML  \n",
       "Datetime                                                 \n",
       "2021-10-11 09:32:00-04:00  0.001752 -0.001094  0.001791  \n",
       "2021-10-11 09:34:00-04:00 -0.001710  0.000199 -0.000463  \n",
       "2021-10-11 09:36:00-04:00 -0.000403 -0.000388  0.001155  \n",
       "2021-10-11 09:38:00-04:00 -0.000324 -0.000832  0.001345  \n",
       "2021-10-11 09:40:00-04:00 -0.001392 -0.000229  0.000156  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WML.to_csv(\"winner_loser_spread_data.csv\")\n",
    "WML = pd.read_csv(\"data/winner_loser_spread_data.csv\", index_col = 0)\n",
    "WML.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies_30m_beaters = sp500_30m_sharpe_excess.copy()\n",
    "dummies_30m_beaters[dummies_30m_beaters >= 0] =1\n",
    "dummies_30m_beaters[dummies_30m_beaters < 0] =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datetime\n",
       "2021-10-11 10:00:00-04:00    0.154455\n",
       "2021-10-11 10:30:00-04:00    0.803960\n",
       "2021-10-11 11:00:00-04:00    0.594059\n",
       "2021-10-11 11:30:00-04:00    0.398020\n",
       "2021-10-11 12:00:00-04:00    0.906931\n",
       "                               ...   \n",
       "2021-11-17 13:30:00-05:00    0.201980\n",
       "2021-11-17 14:00:00-05:00    0.831683\n",
       "2021-11-17 14:30:00-05:00    0.295050\n",
       "2021-11-17 15:00:00-05:00    0.758416\n",
       "2021-11-17 15:30:00-05:00    0.762376\n",
       "Length: 363, dtype: float64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This is the prob of 15 min winning\n",
    "dummies_30m_beaters.T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#slice 2m spread data by 15 rows, and measure beta for each 15 rows (15 mins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine betas measured above with 15 min prob of beating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regress prob of beating on observed betas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
